

# 导言



> 我不想在这里掩盖一个事实：在这些规则的具体应用中，我预见到会发生许多事情，如果不谨慎行动，可能会犯严重的错误。
> 
> 
>  ——詹姆斯·伯努利（James Bernoulli, 1713, 第四部分第3章\[1]）


我们在上一篇博客[《概率论沉思录：初等假设检验》](https://github.com)中介绍了采用贝叶斯方法进行假设检验。其中，我们提到了公式：


P(H∣DX)\=P(H∣X)P(D∣HX)P(D∣X)其中X为先验信息，H为待检验的假设，D为数据。该公式是我们试图从数据中得出结论的一大类科学推断问题背后的基本原理。


在这一篇博客中，我们将看下采用贝叶斯方法进行的假设检验在实践中是如何表现的。我们将讨论一些概率论的“怪异”应用\[2]\[3]。所谓“怪异”，即“偏离常规”，没有正确地使用概率论导致了错误。大概任何全新的应用都必须经过这种类似的怪异探索阶段。在许多情况下，我们认为今天的怪异应用可能成为明天受人尊敬的有用应用。我们将会使用贝叶斯分析来重新考虑这些问题，并消除掉其中的“怪异”，获得一些有用的结论。


在这一篇博客中，我们将用概率论来测量我们对各种假设的信念。我们将会看到，**除了数据之外，备择假设、对假设先验概率的分配、对数据的解释方式等等也会对我们对假设的信念产生重要的影响**。其中，我们会提到我们在上一篇博客中提到过的“死假设复活”现象。我们将会看到：无论后续数据给出的证据如何，一个始于−100dB的假设A可能永远难以令人置信，因为几乎肯定有许多其它假设(B1,B2,⋯)的可能性比它的更高，也许是−60dB。这样，当我们获得可能“复活”假设A的惊人数据时，这些备择假设也可能“复活”（我们在下文的心灵感应和海王星的发现的例子中将看到这一点）。


# 1 斯图尔特夫人的心灵感应能力


我们现在来测量我们对特异功能（extrasensory perception, ESP）的信念有多强。假定我们对特异功能的初始信念为−100dB。如果我们遇到一个人，能够正确猜出我们背着他写下的数1000次，我们是否就会相信他具有特异功能呢？


考虑如下关于格洛丽亚·斯图尔特夫人的心灵感应能力的一个实验。在该实验的报告中，根据实验设计，如果随机猜测的话，每次能正确猜出一张卡片的概率都是p\=0\.2，并且在每次试验中是独立的。根据这个信息，我们可以得到在n次试验中随机猜测且猜测成功的次数r服从二项分布b(r∣n,p)（参见博客[《概率论沉思录：初等抽样论》](https://github.com)）。令「Hp：只有纯粹偶然性在起作用」为零假设。根据二项分布，如果受试者没有特异功能，则n次试验中猜测成功的次数r约为\[(均值)±(标准差)]：


(r)est\=np±√np(1−p)对于n\=37100次试验，结果约为7420±77。


但是，据报告，格洛丽亚·斯图尔特夫人在37100次试验中猜对了9410次，成功率f≈0\.2536。这些数值构成了我们的实验数据D。乍一看，这些数据并不引人注目。但请注意，她的得分与机会期望相差


9410−742077≈25\.8个标准差。


我们现在想对我们的零假设Hp进行检验，看下以这个假设为条件能否生成我们的实验数据。对于数据D，假设Hp的似然可以表示为下列抽样分布：


Lp\=P(D∣Hp)\=(nr)pr(1−p)n−r我们想计算这个似然Lp是多少，但是数值n和r太大，我们需要使用二项分布的斯特林近似值：


P(D∣Hp)\=Aexp{nH(f,p)}其中


H(f,p)\=Efln(pf)\=fln(pf)\+(1−f)ln\[1−p1−f]为观测分布(f,1−f)相对于期望分布(p,1−p)的相对熵，A≡√\[n2πr(n−r)]。



> **注**：这里相对熵的定义H(f,p)\=Efln(pf)和信息论里相对熵的定义H(f,p)\=Efln(fp)不太一样，导致这里的相对熵按定义有H(f,p)⩽0。考虑到作者的物理背景，我去查了中科大统计力学的讲义\[4]（好像Staff服务器临时宕机了，不过可以在Wayback Machine里面查看），发现统计力学里相对熵的定义确实是⩽0的。我认为可能是为了保持和熵的定义H(p)\=−Eplnp的类似性，所以才将相对熵定义为H(f,p)\=−Efln(fp)\=Efln(pf)⩽0。


在我们这个例子中观测分布(f,1−f)≈(0\.2536,0\.7464)，期望分布(p,1−p)\=(0\.2000,0\.8000)，则H(f,p)≈−0\.008452，又因为A≈0\.00476，于是


Lp\=P(D∣Hp)\=0\.00476exp{−313\.6}≈3\.04×10−139这个数值非常小，说明如果斯图尔特夫人如果仅仅依靠随机猜测的话，几乎不可能得到我们的实验数据。那么，如果假设斯图尔特夫人具有心灵感应。能否产生更大的似然呢？


考虑伯努利类型的备择假设Hq(0⩽q⩽1)，它也假设试验是独立的，不过为斯图尔特夫人分配了与p\=0\.2不同的成功概率q（如果认为她具有心灵感应，则q\>0\.2）。当q\=f≈0\.2536时，H(f,q)\=0达到最大值（注意这里的H(f,q)⩽0），此时似然也达到最大值。我们记此时的假设为Hf，则最大似然为


Lf\=P(D∣Hf)\=A≈0\.00476因此，如果机器人知道斯图尔特夫人的心灵感应能力可以达到q\=0\.2536的程度，那么机器人就会认为她生成所观测到数据的可能性不会很小。我们可以计算假设Hp和假设Hf的似然比：


LpLf\=P(D∣Hp)P(D∣Hf)\=exp{−313\.6}≈6\.39×10−137我们发现这两个假设的似然比非常小。如果仅根据这个结果的话，机器人应该报告：“相对于Hp，数据的确极大地支持了Hf。”



> **注** 关于这里的所采用的二项分布的正态近似，如果使用我们在上一篇博客[《概率论沉思录：初等假设检验》](https://github.com)中得到的二项分布的正态近似值
> 
> 
> P(D∣Hp,X)≈(常数)×exp{−n(f−p)22p(1−p)}可能会产生较大的误差。在这里使用它的话，我们将得出似然比exp{−333\.1}。而exp{−333\.1}\<exp{−313\.6}，也就意味着正态近似值会使斯图尔特夫人看上去比数据显示得更加神奇，额外的几率因子为
> 
> 
> exp{−313\.6}exp{−333\.1}\=exp{333\.1−313\.6}\=exp{19\.5}≈2\.94×108


如果我们用概率论比较Hp和Hf，则斯图尔特夫人具有特异功能的程度达到q\=f≈0\.2536的后验概率是


P(Hf∣DX)\=P(Hf∣X)P(D∣HfX)P(D∣X)\=PfLfPfLf\+PpLp其中Pp和Pf分别为Hp和Hf的先验概率。但是，由于Lp≪Lf，先验概率是多少几乎无关紧要。再加上对于特异功能研究人员而言，Pf\=P(Hf∣X)不会特别小，此时P(Hf∣DX)≈1。


特异功能研究人员会认为这是压倒性的证据，但我们仍会坚持不相信特异功能。为什么我们在面对上述结果时，仍然会有如此坚定的想法呢？


问题在于，上述计算（参见式(1)和式(2)）代表了概率论非常朴素的应用，**因为它们仅考虑了Hp和Hf，而没有考虑其它假设**。


现在假定Hp,Hf,Lp,Lf,Pp,Pf的定义和上面一样，但我们引入一些关于该实验报告可能如何产生的新假设。这些新假设(H1,H2,⋯,Hk)的产生可能是无意的，例如非故意的记录错误；也可能是无聊的（斯图尔特夫人采用了一些作弊手段）；也可能是不那么无意的，例如选择数据（不报告斯图尔特夫人状态欠佳日子里的数据），甚至可能源于故意伪造整个实验来达到某些目的。所有这些，我们都称之为“欺骗”。设欺骗假设具有的似然概率和先验概率分别为Li和Pi，其中i\=(1,2,⋯,k)。


在这个新的逻辑环境中，之前得到压倒性支持的假设Hf的后验概率变为


P(Hf∣DX)\=PfLfPfLf\+PpLp\+∑PiLi其中，Lp≈3\.04×10−139，导致PpLp可以忽略不计。于是，要使P(Hf∣DX)接近于1，就需要∑iPiLi≪PfLf。让我们假定欺骗假设的似然Li与Lf≈0\.00476的数量级相同（也即意味着欺骗机制可以像真正具有心灵感应能力的斯图尔特夫人一样容易地产生报告中的数据），那么要使P(Hf∣DX)接近于1，就需要


∑iPi≪Pf但是根据我们的判断，每一个欺骗假设Hi都比Hf更有可能，因此上述不等式成立的可能性不大。


因此，这种实验永远无法让我们相信斯图尔特夫人具有特异功能的真实性。这并不是因为我们一开始就断言Pf\=0，而是**因为实验的数据D可以被许多替代假设解释，我们认为其中每一个都比Hf更合理，且根据提供给我们的信息，其中没有一个可以被排除**。


# 2 意见分歧与趋同


假设A和B两个人（由于先验信息不同）对于某件事，比如某个有争议的命题S的真假有不同的看法。现在同时给他们一系列的新信息或数据D1,D2,⋯,Dn，其中一些对S有利，一些对S不利。随着n的增大，他们的信息总量变得几乎相同，因此我们可能会期望他们对S的观点趋于一致。


我们采用概率论来分析这种想法的合理性。设IA和IB表示A和B的先验信息，A最初是支持者，B最初是怀疑者，则他们的先验概率为：


P(S∣IA)≈1,P(S∣IB)≈0接下来我们考虑接收到数据D后，他们的后验概率是多少。如果D支持S，由于A几乎已经确定S为真，所以


P(S∣DIA)≈P(S∣IA)≈1数据D对A的意见没有明显的影响。不过，如果B合理地进行推理，则会有


P(S∣DIB)\>P(S∣IB)B的观点会朝A的观点的方向改变。


同理，如果D倾向于否定S，则可以期望B的观点不会因此明显改变，而A的观点将朝B观点的方向改变。由此我们可能推测，无论新信息D是什么，它都应该倾向于使不同的人达成共识，也即


\|P(S∣DIA)−P(S∣DIB)\|\<\|P(S∣IA)−P(S∣IB)\|尽管这在特殊情况下得到了验证，但在通常情况下并非如此。


例如，在公共问题的讨论中，我们多次观察到，一些有争议的问题被活跃地讨论一段时间后，社会会逐渐分化为两个极端阵营，很难找到保持观点中立的人。比如知乎上关于俄乌战争，或者更早些的关于防疫的政策的讨论等等。


我们想知道概率论能否解释这种分歧，并指出人们可能在以合情的贝叶斯方法（即与其先验信息和先验信念一致的方式）进行思考。为了比较A和B两人的推理，我们将A和B的后验概率进一步用贝叶斯公式表示：


P(S∣DIA)\=P(S∣IA)P(D∣SIA)P(D∣IA)P(S∣DIB)\=P(S∣IB)P(D∣SIB)P(D∣IB)并用对数形式重写上述式子：


ln\[P(S∣DIA)P(S∣DIB)]\=ln\[P(S∣IA)P(S∣IB)]\+ln\[P(D∣SIA)P(D∣IB)P(D∣SIB)P(D∣IA)]这可以用用一个简单的助记等式来描述：


ln(后验)\=ln(先验)\+ln(似然)式(4)与我们在上一篇博客[《概率论沉思录：初等假设检验》](https://github.com)中提到的对数几率公式不同的是，这里的归一化因子P(D∣IA)和P(D∣IB)没有被消掉，这是因为在上一篇博客中我们在给定相同先验信息的条件下比较不同的假设，消掉了归一化因子P(D∣I)，但是**这里我们根据不同的先验信息考虑一个固定的假设S**，归一化因子不会被消掉。


由于P(S∣IA)≈1,P(S∣IB)≈0，因此ln(先验)\>0，那么我们可以针对似然项的不同情况做以下的分类讨论：


1. ln(似然)\<0，且\|ln(似然)\|\<\|ln(先验)\|：此时ln(后验)→0（单调），意味着在对数刻度上他们的观点将收敛（趋同）；
2. ln(似然)\>0：此时ln(后验)→∞（单调），意味着在对数刻度上他们的观点将发散（分歧）；
3. ln(似然)\<0，且\|ln(先验)\|\<\|ln(似然)\|\<2\|ln(先验)\|：此时ln(后验)→−ln(先验)（单调），意味着在对数刻度上他们的观点将收敛且反转；
4. ln(似然)\<0，且\|ln(似然)\|\>2\|ln(先验)\|：此时ln(后验)→−∞（单调），意味着在对数刻度上他们的观点将发散且反转；


看起来，概率论原则上可以允许信息D对两人信念的相对状态产生各种可能的影响。


但是，也许还有尚未注意到的其它约束使其中一些结果无法实现。我们接下来尝试对这四种行为提供具体的示例。


设新信息D：「N在电视上耸人听闻地宣称一种常用药物是不安全的」，且A、B、C三名观众都看到了。他们对于该药物安全的先验概率P(S∣I)分别为(0\.9,0\.1,0\.9)，即最初A和C相信该药物是安全的，B不相信。


我们设他们对信息D的解释方式不同，这来源于他们对N可靠性的不同看法。他们都同意，如果药物真的被证明是不安全的，N会在电视上大声疾呼该药物不安全，也即似然P(D∣¯SI)分别为(1,1,1)。但是，A相信N是诚实的，C不相信。如果药物是安全的，他们认为N说它不安全的概率P(D∣SI)分别为(0\.01,0\.3,0\.99)。由公式


P(S∣DI)\=P(S∣I)P(D∣SI)P(D∣I)\=P(S∣I)P(D∣SI)P(D∣SI)P(S∣I)\+P(D∣¯SI)P(¯S∣I)得出他们对该药物安全的后验概率分别约为(0\.083,0\.032,0\.899)。


A和B意见的变化趋势与我们在式(3)中的猜测是一致的：对该药物安全的信念都显著降低了（虽然对B而言只是加强了他原有的不安全信念），因为两人都愿意在一定程度上相信N的诚实。而C和A、B的变化趋势不同的原因在于他们对信息D可信程度的看法不同。因此，造成分歧的原因之一为即使是对于同样的信息，不同的人对信息D的解释也会具有差异。


但是，这不是造成分歧的唯一原因，不同的人对命题所分配的先验概率也会对结果产生影响。我们引入另外两个人X和Y，与A、B、C不同的是，他们对N的判断是一致的：


P(D∣SIX)\=P(D∣SIY)\=a,P(D∣¯SIX)\=P(D∣¯SIY)\=b此时，他们的观点总是朝着同一方向改变，而且由对数几率公式可知，在证据尺度上总是以相同的量ln(a/b)变化。但是，对于药物的安全性，他们分配了不同的先验概率：


P(S∣IX)\=x,P(S∣IY)\=y我们在这里不妨设x\>y（x\<y的情况同理）。


根据x,y,a,b的赋值情况，他们的观点既可能收敛，也可能发散。我们采用式(4)中的做法来表示出它们后验概率P(S∣DIX)与P(S∣DIY)比值的对数形式：


ln\[P(S∣DIX)P(S∣DIY)]⏟后验\=ln\[xy]⏟先验\+ln\[ay\+b(1−y)ax\+b(1−x)]⏟似然由于x\>y，因此ln(先验)\>0，那么我们可以像之前一样，针对似然项的不同情况做以下的分类讨论：


1. ln(似然)\=0：代入可得a\=b，此时$\\ln (\\text{后验}) \= \\ln (\\text{先验}) ，在这个例子里也就意味着他们认为N完全不可靠，N$的证词也没有改变他们的观点；
2. ln(似然)\<0，且\|ln(似然)\|\<\|ln(先验)\|：代入可得a\>b，此时ln(后验)→0（单调），ln(a/b)\>0，在这个例子里也就意味着他们会认为N说的话含有欺骗的成分，以至于他们的观点朝与N的意图相背的方向趋同（一个极端情况是如果b→0，则ln(a/b)→∞，即他们认为N肯定在撒谎，因此不论他们先验概率是什么，都会完全相信药物的安全性）；
3. ln(似然)\>0：代入可得a\<b，此时ln(后验)→∞（单调），ln(a/b)\<0，在这个例子里也就意味着他们会认为N说的话含有可信的成分，他们的观点朝N的意图方向变化，但由于P(S∣DIY)以更快的速度→0，以至于产生分歧（一个极端情况是如果a→0，则ln(a/b)→−∞，即他们认为N肯定是诚实的，因此不论他们先验概率是什么，都会完全相信药物是不安全的）；
4. ln(似然)\<0，且\|ln(先验)\|\<\|ln(似然)\|\<2\|ln(先验)\|：代入可得a\>b且x\<y，这是不可能的，在这个例子里也就意味着如果x\>y，他们的观点不会出现收敛且反转的现象；
5. ln(似然)\<0，且\|ln(似然)\|\>2\|ln(先验)\|：代入可得a\>b且ab\<1−(1x\+1y)\<0，这是不可能的，在这个例子里也就意味着如果x\>y，他们的观点不会出现发散且反转的现象；


我们看到，用做为逻辑的概率论可以导出意见分歧的可能。但是，导致我们猜测式(3)的推理错误在哪里呢？因为我们假设了“数据D支持假设S”是D和S的绝对性质，以一种微妙的形式犯了思维投射谬误——**这个关系实际上是相对的，D是否支持S取决于数据接受者的先验信息，这将导致他们对S的不同先验概率，和对D的不同解释方式**。


# 3 视觉感知——进化出“贝叶斯性”？


有一类关于错觉的心理学实验和我们所讨论的贝叶斯理论也很有关联。这些实验的设计者对其进行了巧妙的设计，使人们“看到”了与现实截然不同的事物，包括错误判断物体的大小、形状和距离等等（参见复旦哲院王球老师的读书会分享：[王球：贝叶斯知觉心理学](https://github.com)）\[5]。比如对于下面这幅图\[5]，你觉得左边和右边的图形哪个是凸起的，哪个是凹下的呢？



![](https://images.cnblogs.com/cnblogs_com/blogs/538207/galleries/2106514/o_241228084611_%E7%8E%8B%E7%90%83%EF%BC%9A%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9F%A5%E8%A7%89%E5%BF%83%E7%90%86%E5%AD%A6.png)



多数人会觉得左边的图形是凸起的，右边的图形是凹下的（不过我第一次看的时候觉得右边的图形是凸起的，右边的图形是凹下的。。。）。贝叶斯知觉心理学对此的解释是，我们的视觉系统的加工，并不是纯粹去被动地接受外部环境的信号，而是主动地在做一些隐式的推断（本质上相当于我们在这里研究的推断）。外部环境的信息往往是不完整的，但**我们的知觉系统会基于这些不完整的信息，去对环境情况进行估计**。


在这个例子里，当我们看到这幅图的时候，光打到我们视网膜上会产生一些近端刺激，但我们的知觉系统没办法去确定下来究竟是什么样的外部环境原因导致我们现在接收到这样的一个信号刺激。也就是说，外部的环境情况究竟是什么样的，我们的近端刺激没办法去确定下来。但是，我们的知觉系统仍然会给我们一个确定的推断结果。


关于这个问题，我们在之后会单独开一篇博客进行讲述。


# 4 海王星的发现


概率论的另一种潜在应用已经被哲学家激烈地讨论了一个多世纪，他涉及科学家的推理过程。通过该推理过程，科学家根据观察到的事实接受或拒绝自己的理论。我们在博客[《概率论沉思录：合情推理》](https://github.com)中提到，这主要包括使用两种形式的三段论：


一强:{A真则B真   B假\_A假}一弱:{A真则B真   B真\_A变得更合情}在博客[《概率论沉思录：定量规则》](https://github.com)中，我们注意到这对应于贝叶斯定理的两种形式的应用：


P(A∣¯BX)\=P(A∣X)P(¯B∣AX)P(¯B∣X),P(A∣BX)\=P(A∣X)P(B∣AX)P(B∣X)在第一种形式中，由P(¯B∣AX)\=0，得到P(A∣¯BX)\=0；在第二种形式中，由P(B∣AX)\=1，P(B∣X)⩽1，得到P(A∣BX)⩾P(A∣X)。这些形式确实与三段论在定性上是一致的。


我们接下来考虑上述的第二种形式是否给出了令人满意的**弱三段论定量版本**，方便科学家在实践中使用。我们以海王星的发现为例子。


1781年，赫歇尔发现了天王星。在几十年内（即当天王星绕过其轨道的三分之一时），它很明显并不完全遵循牛顿理论（力学和引力定律）规定的路径运行。在这一点上，强三段路的朴素应用可能导致一个牛顿理论被推翻了的结论。但是，牛顿理论在许多其它方面的成功使其具有牢固的地位，以至于在天文学家的脑海中这个假设的可能性很低：“牛顿理论是错误的”这种可能性已经降低到大概−50dB。因此，对于法国天文学家勒韦里耶（1811\-1877）和英国剑桥学者亚当斯（1819\-1892）来说，也许降低到−20dB的另一种假设“复活”了：必定存在天王星以外的另一个行星，其引力引起了这种差异。


勒韦里耶和亚当斯在不知道彼此工作的情况下，独立计算了可能导致所观测偏差的行星的质量和轨道，并预测在哪里可以发现这颗新行星。两人的结果几乎相同。1846年9月23日，柏林天文台收到勒韦里耶的预测。当晚，在柏林天文台工作的天文学家加勒在预测位置的大约1°之内发现了新行星（海王星）。


通过这个插曲，我们会本能地认为牛顿理论的合情性增加了。问题是，增加了多少？我们将用概率论来对该问题进行建模。


我们设T代表牛顿理论，N代表勒韦里耶经过验证的那部分预测结果。那么，概率论给出T的后验概率为


P(T∣NX)\=P(T∣X)P(N∣TX)P(N∣X)\=P(T∣X)P(N∣TX)P(N∣TX)P(T∣X)\+P(N∣¯TX)P(¯T∣X)关注最后一个等式，我们发现我们需要考虑P(N∣¯TX)。但是，这个量我们还没有定义。在我们指定牛顿理论的替代理论之前，命题¯T≡“牛顿理论是错误的”没有明确的意义。


为了认识到替代理论对问题结果的影响，我们考虑以下两种特殊情况：


* 如果仅存在一个可能的备择理论，且根据该理论天王星之外没有行星，则P(N∣¯TX)\=0。此时，概率论再次简化为演绎推理，给出P(T∣NX)\=1，牛顿理论成立。
* 如果爱因斯坦理论是唯一可能的备择理论，那么对于这一现象，其预测结果和牛顿理论的预测结果不会有显著的差异，将得到P(N∣¯TX)\=P(N∣TX)，于是P(T∣NX)\=P(T∣X)，牛顿理论的合情性不变。


因此，对勒维里耶\-亚当斯预测结果的验证，可能会将牛顿理论提升到确定的程度，也可能对其合情性完全没有影响。这完全取决于：**我们在检验牛顿定律时使用了哪种特定的替代理论**。



> **注** 对于正在评估自己理论的科学家而言，这个结论可以根据常识得出。我们已经在上一篇博客[《概率论沉思录：初等假设检验》](https://github.com)中详细介绍其中的数学原理。只不过对于科学家而言，他们不需要任何数学原理就能直观地看到同样的结果。


我们考虑替代理论H1：「天王星以外还存在一颗行星，但它在天球上所有方向上的可能性相同」。然后，由于1°角的圆锥体在天空中填充大约π/57\.32\=10−3球面度，因此P(N∣H1X)≈10−3/4π\=1/13000，这是海王星将在预测位置1°以内的概率。



> **注** 球面度\[6]，也称立弳（英语：steradian，符号sr）是立体角的国际单位。它可算是三维的弧度。
> 
> 
> 
> ![](https://images.cnblogs.com/cnblogs_com/blogs/538207/galleries/2106514/o_241227073023_%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%EF%BC%9A%E7%90%83%E9%9D%A2%E5%BA%A6.png)
> 
> 
> 
> 以r为半径的球的中心为顶点，若展开的立体角所对应的球面表面积为r2，该立体角的大小就是一球面度。球表面积为4πr2，因此整个球有4π个球面度（这也是为什么我们上面算P(N∣H1X)的时候为什么要除以4π）。


波利亚在考虑此问题时，在计算中没有区分P(N∣X)和P(N∣¯TX)。他想依据公式P(T∣NX)\=P(T∣X)P(N∣TX)P(N∣X)计算T的后验概率与先验概率的比值，但他并没有计算P(N∣TX)P(N∣X)，而是计算的


P(N∣TX)P(N∣¯TX)\=P(N∣TX)P(N∣H1X)\=13000这样，波利亚就发现牛顿理论为真的概率增加了13000倍，那么先验概率必然低于1/13000。然而，这与常识矛盾，因为牛顿理论在勒维里耶出生之前就已经很成熟了。波利亚在他的书中将其解释为，这揭示了贝叶斯定理的不一致性以及试图对其进行数值化应用的危险。


不过我们知道，这个比值实质上是T的后验几率和先验几率之比：


O(T∣NX)O(T∣X)\=P(N∣TX)P(N∣¯TX)此时得出的结论将令人满意。说明如果仅考虑H1做为备择假设的话，则对预测结果的验证会使牛顿理论的证据增加10log10(13000)≈41dB。


这个例子说明了当我们更仔细地研究问题时，可以如何消除在文献中发现的对贝叶斯\-拉普拉斯方法的异议。然而，该例子同时也表明，科学家在实践中面临的情况如此复杂，以至于几乎没有希望通过应用贝叶斯定理来给出有关理论相对优劣的定量结果。事实上也几乎没有必要这样做，因为科学家面对的真正困难不在于推理过程本身，他们的推理过程运用常识就够了。真正的困难在于，学习如何得到更符合事实的新的替代方案。


# 5 赛马和天气预报


前面的示例指出了推断问题可能会具有的两个特点：（a）在特异功能和心理学的案例中，我们收到的信息通常不是直接声明S为真的命题，而是间接声明S为真，信息来源本身并不完全可靠；（b）就像海王星的例子中那样，人们可能误用贝叶斯定理，并得出贝叶斯定理错误的结论。普林斯顿大学的哲学家杰弗里的工作同时存在这两个特点。以下用RCJ来表示哲学家杰弗里。


RCJ考虑了以下问题。仅使用先验信息I，我们为A分配一个概率P(A∣I)。然后得到新信息B，根据贝叶斯定理它会变为


P(A∣BI)\=P(A∣I)P(B∣AI)P(B∣I)但是之后，他认为贝叶斯定理还不够一般化，因为我们经常收到不确定的新信息，也许B的概率不是1而是q。为此，我们会回应：“如果你不接受B为真，为什么要以这种方式在贝叶斯定理中使用它呢？”但RCJ犯了一个常见的错误：不是由于错误地应用上式中的不确定性信息而误用了贝叶斯定理，而是贝叶斯定理本身就是错误的，需要将其一般化以考虑新信息的不确定性。


他提出的一般化方案是将A的更新概率视为以下加权平均值：


P(A)J\=qP(A∣BI)\+(1−q)P(A∣¯BI)但是，就像我们之前提到过的，这是一种特定方案（ad hockery），而不是依据概率论规则，除非我们将q视为先验概率P(B∣I)。然而，这正是RCJ想排除的情况（因为这时P(A)J\=P(A∣I)，并没有更新）。


由于RCJ提出的“一般化”公式与概率论规则冲突，我们知道它必然违反了我们在博客[《概率论沉思录：合情推理》](https://github.com)和[《概率论沉思录：定量规则》](https://github.com)中讨论过的合情条件之一。事实上，我们可以学习很多不同的东西，不只是新信息B。RCJ提出的更新方式对B而言是这样的，但对其它信息则可能不然。RCJ提出的“一般化”公式违反了我们在博客[《概率论沉思录：合情推理》](https://github.com)中提到的合情条件(Ⅲb)：非意识形态性，因为**它没有考虑所有新信息**，仅考虑了与B相关的部分。


我们在博客[《概率论沉思录：定量规则》](https://github.com)中的分析告诉我们，如果要扭转现状并得到一个有确定答案的良好定义的问题，那么我们绝不能背离贝叶斯定理。如果不确定B为真，那么就不能用B做为新信息。实际收到的信息一定是某个命题C，使得P(B∣CI)\=q。此时，我们当然应该考虑以C而不是以B为条件的贝叶斯定理：


P(A∣CI)\=P(A∣I)P(C∣AI)P(C∣I)如果正确应用，贝叶斯定理会自动考虑含有不确定性的新信息。因为上述A的更新概率可以使用概率论的加法规则和乘法规则写为：


P(A∣CI)\=P(AB∣CI)\+P(A¯B∣CI)\=P(A∣BCI)P(B∣CI)\+P(A∣¯BCI)P(¯B∣CI)如果我们定义q≡P(B∣CI)为B的更新概率，则可以写成


P(A∣CI)\=q(A∣BCI)\+(1−q)P(A∣¯BCI)这类似于RCJ提出的“一般化”公式，但通常不等于它，除非我们添加概率P(A∣BCI)和P(A∣¯BCI)与C无关的限制。直觉上，如果添加了该限制，我们这里的逻辑流是


(C→B→A)也即C仅通过与B的中介才与A相关。RCJ考虑的其实是我们这里的特殊情况，不过他没有考虑到这个结果其实可以由贝叶斯定理推导出。此外，他没有考虑到逻辑流


(C→A)即无论B是否为真，C与A直接相关。这也就意味着他没有考虑到所有的新信息，而只考虑了C经过B的中介与A关联的那部分信息。


我们可以通过另一种场景来更实际地说明这一点。考虑以下命题：


* A：我的马明天将赢得比赛。
* B：赛道将变得泥泞。
* I：我对自己的马和骑师的特别了解，以及对马、骑师、比赛和生活的一般了解。


概率P(A∣I)在接收天气预报的结果后更新。这样，命题


* C：天气预报员向我们展示今天的天气图，引用一些当前的气象数据，然后通过未经解释的方式分配了明天下雨的概率q′。


明显存在，但RCJ没有意识到并加以说明。如果上面定义的C是新信息，那么我们还必须根据所有的现有信息，考虑C可能如何通过赛道上的泥泞B以外的其它情况影响比赛A的结果。也许骑师会因为耀眼的阳光眼花，也许（无论赛道是否潮湿）马在多云的日子里都跑得不好，这些将是RCJ提出的“一般化”公式无法考虑的(C→A)形式的逻辑关系。


这个例子也说明了日常生活中的常见问题可能比科学问题复杂得多。在科学问题中，我们经常研究精心控制的情况；而最熟悉的问题可能非常复杂（仅仅因为结果取决于许多未知且不受控制的因素）以至于尽管在原则上是正确的，但是在实践中完全无法进行完整的贝叶斯分析。后者的计算成本远远超出了我们希望通过赛马赢得的赌注。


那么，我们必然使用近似技巧。既然不能精确地应用贝叶斯定理，我们是否仍需要考虑它？答案是肯定的。因为贝叶斯定理仍然是告诉我们应该寻找什么的规范性原则。没有它，我们将没有指导选择的依据，也没有判断其成功与否的标准。


# 6 关于直觉的悖论


我们认为，做为扩展逻辑的概率论规则的定量使用是已知进行推断的唯一合理方法，没有严格遵守这些规则是多年以来一直导致不必要的错误、悖论和争议的原因。关于直觉的悖论有一个著名的例子，称为亨佩尔悖论，它的前提是「假设的一个示例支持该假设」，然后内容是「所有乌鸦都是黑色的假设在逻辑上等价于所有非黑色物体都不是乌鸦的命题，于是观察到一只白鞋会支持这个假设」。这种看似正确（但最终得出令人无法认同的结论）的论点，已经有很多记载。


这里的问题在于，亨佩尔通过试图在不考虑任何备择假设的情况下判断假设的真假，导致其前提错误。可以通过一个简单的反例证明这个前提中的错误。我们设有以下两个世界：


* 世界1：其中有100万只鸟，其中有100只乌鸦且都是黑乌鸦。
* 世界2：其中有200万只鸟，其中有20万只黑乌鸦，180万只白乌鸦。


现在假定我们观察到一只黑乌鸦，请问我们处在哪个世界？


根据对数几率公式，观察到一直黑乌鸦可以为假设A：「我们处在世界2」给出


10log10(20000/2000000100/1000000)\=30dB的证据，以1000:1的几率反对假设B：「我们处在世界1」。实际上，**“假设的实例”是否支持该假设取决于所考虑的替代假设和先验信息**。


上述的例子也在一定程度上反应了哲学和科学的区别。有人评价道：“哲学家可以自由地做自己喜欢的事，因为他们不需要做对任何事情”（233）。但是，一位负责任的科学家没有这种自由，他不会仅仅依靠自己的直觉就断言一个一般原则是正确的，并要求其它人采纳它。


# 7 贝叶斯法理学


我们接下来考虑贝叶斯方法在法理学上的应用。假定纽约市有人犯了谋杀罪，我们起初不知道是谁，但是知道纽约市有1000万人口。在没有其它信息的前提下，e(有罪∣X)\=−70dB就是任何特定的人有罪的合理信念。


假定现在我们知道某个人有动机，则他有罪的证据大小会变为


e(有罪∣有动机)\=e(有罪∣X)\+10log10\[P(有动机∣有罪)P(有动机∣无罪)]由于P(有动机∣有罪)≈1（也即我们认为犯罪者几乎不可能完全没有动机），因此，上式变为


e(有罪∣有动机)≈e(有罪∣X)−10log10P(有动机∣无罪)因此，一个人有动机对他的定罪产生多大影响几乎完全取决于一个无罪的人也有动机的概率P(有动机∣无罪)。


假设一位非常开明的法官已经意识到了该事实，在引入嫌疑人动机的证据时，他指示助手为陪审团确定纽约市有多少人有动机。如果有动机的人数是Nm，那么


P(有动机∣无罪)\=P(有动机且无罪)P(无罪)\=Nm−1(纽约市人口−1)≈10−7(Nm−1)（上述式子中的−1意思为扣除掉真正的犯罪者，也即有罪且有动机的人）


于是，式(5)将简化为


e(有罪∣有动机)≈−10log10(Nm−1)可以看到纽约市人口从公式中消失了。一旦我们知道有动机的人数，城市有多大就不再重要了。请注意，即使Nm只有1或2，上式也仍然适用：当Nm\=1时，e(有罪∣有动机)可视为∞（全纽约市只有嫌疑人一个人有动机，那犯罪者肯定就是他了）；当Nm\=2时，e(有罪∣有动机)≈0（已知在纽约市除了嫌疑人之外还有一个人有动机，我们无法确定谁是犯罪者）


如果进一步思考其物理意义，我们会发现这挺有趣。例如，如果我们现在得知不久前有人在犯罪现场附近看到了嫌疑人，则其意义几乎完全取决于附近还有多少无辜者。



> **注** 在上面这个例子中，我们试图根据不完整的信息判断亚里士多德命题的真实性，即被告是否进行了明确定义的行动。这是做为逻辑的概率论被设计适用的情况。但是，其它法律情况就可能大不相同了。例如，在医疗事故诉讼中，问题在于被告是否进行了合理判断。由于没有关于“合理判断”的正式、精确定义，因此问题不是亚里士多德命题的真假命题（但是，如果确定他故意违反了我们在博客[《概率论沉思录：合情推理》](https://github.com)中提到的合情推理要求之一，我们认为大多数陪审团成员会认为他有罪）。但是，这并不意味着概率论不适用于这种情况，我们认为在这种情况下相比于真相我们更关心价值判断，后面在讨论决策论和Ap分布与连续法则的时候会回到该主题。


# 参考


* \[1] Schneider I. Jakob bernoulli, ars conjectandi (1713\)\[M]//Landmark Writings in Western Mathematics 1640\-1940\. Elsevier Science, 2005: 88\-104\.
* \[2] Jaynes E T. Probability theory: The logic of science\[M]. Cambridge university press, 2003\.
* \[3] 杰恩斯. 廖海仁译. 概率论沉思录\[M]. 人民邮电出版社, 2024\.
* \[4] [USTC：《高等统计物理：第一章》](https://github.com)
* \[5] [王球：贝叶斯知觉心理学](https://github.com):[蓝猫加速器配置下载](https://yunbeijia.com)
* \[6] [《维基百科：球面度》](https://github.com)


  * [导言](#%E5%AF%BC%E8%A8%80)
* [1 斯图尔特夫人的心灵感应能力](#tid-paSFtX)
* [2 意见分歧与趋同](#tid-4whznE)
* [3 视觉感知——进化出“贝叶斯性”？](#tid-RSXFar)
* [4 海王星的发现](#tid-4JW6n4)
* [5 赛马和天气预报](#tid-rihFB7)
* [6 关于直觉的悖论](#tid-fCrx5A)
* [7 贝叶斯法理学](#tid-XBFGnh)
* [参考](#%E5%8F%82%E8%80%83)

   \_\_EOF\_\_

       - **本文作者：** [猎户座](https://github.com)
 - **本文链接：** [https://github.com/orion\-orion/p/18637935](https://github.com)
 - **关于博主：** 研究生小菜一枚，机器学习半吊子，并行计算混子。
 - **版权声明：** 欢迎您对我的文章进行转载，但请务必保留原始出处哦(\*^▽^\*)。
 - **声援博主：** 如果您觉得文章对您有帮助，可以点击文章右下角**【[推荐](javascript:void(0);)】**一下。
     
